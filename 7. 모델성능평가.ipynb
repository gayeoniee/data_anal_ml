{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f96a1d0",
   "metadata": {},
   "source": [
    "# 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f036938",
   "metadata": {},
   "source": [
    "타이타닉 데이터의 생존여부 분류   \n",
    "- 규칙 : 성별(sex) = 1 생존하지 않은 것으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71dc45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass              # 학습은 하지 않음\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0], 1))        # 기본값은 전부 0 (사망)\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:            # 남자면 0 (사망)\n",
    "                pred[i] = 0\n",
    "            else:                                # 여자면 1 (생존)\n",
    "                pred[i] = 1\n",
    "                \n",
    "        return pred\n",
    "    \n",
    "    # 단순한 룰 기반 모델 (남자 -> 사망, 여자 -> 생존)\n",
    "    # 기계학습 없이 성별만으로 예측하는 가짜 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfc4cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "load_titanic = pd.read_csv('titanic.csv')\n",
    "X_titanic_df = load_titanic.drop('Survived', axis=1)\n",
    "y_titanic_df = load_titanic['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00d299b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행 함수\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)            # 결측치 처리\n",
    "    df = drop_features(df)     # 필요 없는 열 제거\n",
    "    df = format_features(df)   # 범주형 변수 레이블 인코딩\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e4f94d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15456\\2992857979.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15456\\2992857979.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Cabin'].fillna('N', inplace=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15456\\2992857979.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna('N', inplace=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15456\\2992857979.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Fare'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7877094972067039"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)\n",
    "\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "my_pred = myclf.predict(X_test)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8ada1",
   "metadata": {},
   "source": [
    "# 혼동행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e49d1298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92, 18],\n",
       "       [20, 49]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79d1dda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7313432835820896), np.float64(0.7101449275362319))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_test, my_pred), recall_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714a3b7",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀, 랜덤포레스트, KNN의 정밀도, 재현율 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1a3396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 16]\n",
      " [31 38]]\n",
      "0.7374301675977654 0.7037037037037037 0.5507246376811594 0.6178861788617886\n",
      "--------------------\n",
      "[[98 12]\n",
      " [22 47]]\n",
      "0.8100558659217877 0.7966101694915254 0.6811594202898551 0.734375\n",
      "--------------------\n",
      "[[92 18]\n",
      " [16 53]]\n",
      "0.8100558659217877 0.7464788732394366 0.7681159420289855 0.7571428571428571\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "models = {\n",
    "    'knn' : KNeighborsClassifier(n_neighbors=5),\n",
    "    'rf' : RandomForestClassifier(),\n",
    "    'lr' : LogisticRegression(max_iter=3000)\n",
    "}\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "\n",
    "    print(confusion)\n",
    "    print(accuracy, precision, recall, f1)\n",
    "    print('-'*20)\n",
    "    \n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    acc = get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d5ee13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 18]\n",
      " [16 53]]\n",
      "0.8100558659217877 0.7464788732394366 0.7681159420289855 0.7571428571428571\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=3000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred_proba = lr.predict_proba(X_test)  # 클래스별 확률값 반환 -> [사망확률, 생존확률]\n",
    "pos_proba = pred_proba[:,1]  # 양성클래스일 확률 (생존일 확률)\n",
    "\n",
    "threshold = 0.5  # 임계치\n",
    "custom_proba = (pos_proba >= threshold).astype(int)  # 임계치보다 크면 1넣어줌 (True/False -> 1/0 변환)\n",
    "confusion_matrix(y_test, custom_proba)\n",
    "get_clf_eval(y_test, custom_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3541685",
   "metadata": {},
   "source": [
    "# 정밀도와 재현율의 변화\n",
    " 정밀도와 재현율의 불균형이 심할 때, 혹은 비지니스의 요구사항이 있을 때 임계치를 조정해야 함\n",
    "\n",
    " 임계치를 낮추면 정밀도는 낮아지고, 재현율은 올라간다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba6e40d",
   "metadata": {},
   "source": [
    "# 평가결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6221e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7571428571428571)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed2ee5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       110\n",
      "           1       0.75      0.77      0.76        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.80      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred))  # 평가보고서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e16eff7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex        -2.593416\n",
       "Pclass     -0.901628\n",
       "SibSp      -0.368137\n",
       "Embarked   -0.107352\n",
       "Parch      -0.059052\n",
       "Cabin      -0.058762\n",
       "Age        -0.042756\n",
       "Fare        0.001286\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lr.coef_[0], index=X_train.columns).sort_values()  # 피처의 중요도 = 계수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d2b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hi_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
